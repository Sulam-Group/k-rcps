{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "from krcps import Config\n",
    "from krcps import get_uq\n",
    "from krcps import get_procedure\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cal, n_val = 256, 128\n",
    "config_dict = {\n",
    "    \"uq\": \"calibrated_quantile\",\n",
    "    \"loss\": \"01\",\n",
    "    \"bound\": \"hoeffding_bentkus\",\n",
    "    \"epsilon\": 0.1,\n",
    "    \"delta\": 0.1,\n",
    "    \"lambda_max\": 0.5,\n",
    "    \"stepsize\": 2e-03,\n",
    "}\n",
    "\n",
    "rcps_config = Config(config_dict)\n",
    "rcps_config.procedure = \"rcps\"\n",
    "\n",
    "krcps_config = Config(config_dict)\n",
    "krcps_config.procedure = \"krcps\"\n",
    "krcps_config.n_opt = 128\n",
    "krcps_config.gamma = np.linspace(0.25, 0.75, 16)\n",
    "krcps_config.membership = \"01_loss_otsu\"\n",
    "krcps_config.k = 2\n",
    "krcps_config.prob_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_cal + n_val\n",
    "m = 128\n",
    "\n",
    "gt = Image.open(os.path.join(\"assets\", \"ground_truth.jpg\"))\n",
    "gt = TF.to_tensor(gt)\n",
    "x = torch.rand(n, *gt.size())\n",
    "\n",
    "M = (torch.mean(gt, dim=0) >= 0.5).long()\n",
    "mu = x + 0.2 * torch.randn_like(x) * (1 - M) + 0.8 * torch.randn_like(x) * M\n",
    "mu = mu.unsqueeze(1)\n",
    "mu = mu.repeat(1, m, 1, 1, 1)\n",
    "y = torch.randn_like(mu) * 0.1 + mu\n",
    "\n",
    "perm_idx = np.random.permutation(n)\n",
    "cal_idx = perm_idx[:n_cal]\n",
    "val_idx = perm_idx[n_cal:]\n",
    "\n",
    "cal_x, cal_y = x[cal_idx], y[cal_idx]\n",
    "val_x, val_y = x[val_idx], y[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cal_x, m_cal_y = torch.mean(cal_x, dim=1), torch.mean(cal_y, dim=2)\n",
    "m_val_x, m_val_y = torch.mean(val_x, dim=1), torch.mean(val_y, dim=2)\n",
    "\n",
    "rcps = get_procedure(rcps_config)\n",
    "krcps = get_procedure(krcps_config)\n",
    "\n",
    "alpha = 0.10\n",
    "_lambda = rcps(m_cal_x, m_cal_y, uq_dict={\"alpha\": alpha, \"dim\": 1})\n",
    "_lambda_k = krcps(m_cal_x, m_cal_y, uq_dict={\"alpha\": alpha, \"dim\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_uq = get_uq(\"calibrated_quantile\")(m_val_y, alpha=alpha, dim=1)\n",
    "\n",
    "_lambda_l, _lambda_u = val_uq(_lambda)\n",
    "rcps_mu_i = torch.mean(_lambda_u - _lambda_l)\n",
    "print(f\"RCPS, mean interval length: {rcps_mu_i:.4f}\")\n",
    "\n",
    "_lambda_k_l, _lambda_k_u = val_uq(_lambda_k)\n",
    "k_rcps_mu_i = torch.mean(_lambda_k_u - _lambda_k_l)\n",
    "print(f\"K-RCPS, mean interval length: {k_rcps_mu_i:.4f}\")\n",
    "print(\n",
    "    f\"K-RCPS reduces the mean interval length by {100 * (rcps_mu_i - k_rcps_mu_i) / rcps_mu_i:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc(\"animation\", html=\"html5\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16 / 2, 9 / 4))\n",
    "ax = axes[1]\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(r\"$K$-RCPS calibration results ($\\lambda_K,~K=2$)\")\n",
    "im = ax.imshow(_lambda_k, cmap=\"jet\")\n",
    "\n",
    "ax = axes[0]\n",
    "samples = val_y[0]\n",
    "vmin, vmax = torch.quantile(samples, torch.tensor([0.01, 0.99]))\n",
    "samples = (samples - vmin) / (vmax - vmin)\n",
    "samples = torch.clamp(samples, 0, 1)\n",
    "\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"Samples from a diffusion model\")\n",
    "im = ax.imshow(torch.zeros_like(gt).permute(1, 2, 0), cmap=\"gray\", vmin=vmin, vmax=vmax)\n",
    "\n",
    "\n",
    "def _init():\n",
    "    im.set_data(torch.zeros_like(gt).permute(1, 2, 0))\n",
    "    return (im,)\n",
    "\n",
    "\n",
    "def _animate(i):\n",
    "    im.set_data(samples[i].permute(1, 2, 0))\n",
    "    return (im,)\n",
    "\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, frames=m, init_func=_init)\n",
    "anim.save(os.path.join(\"assets\", \"results.gif\"), writer=animation.PillowWriter(fps=60))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
